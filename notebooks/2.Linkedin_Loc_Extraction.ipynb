{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the file in the same folder as the script\n",
    "def save(final_file, job_dict):\n",
    "    if job_dict is None:\n",
    "        print(\"Error: job_dict is None. Nothing to save.\")\n",
    "        return\n",
    "    # Saving the file\n",
    "    try:\n",
    "        with open(f'{final_file}.p', 'wb') as fp:\n",
    "            pickle.dump(job_dict, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print(f\"Data successfully saved to {final_file}.p\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "\n",
    "# Load the file from the same folder as the script\n",
    "def load(file_name):\n",
    "    if not os.path.exists(file_name):\n",
    "        print(f\"{file_name} does not exist. Starting fresh.\")\n",
    "        return {}\n",
    "    \n",
    "    # Loading the file\n",
    "    try:\n",
    "        with open(file_name, 'rb') as fp:\n",
    "            job_dict = pickle.load(fp)\n",
    "        print(f\"Data successfully loaded from {file_name}\")\n",
    "        return job_dict\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from job_dict_full_usa.p\n"
     ]
    }
   ],
   "source": [
    "loaded_job_dict = load(\"job_dict_full_usa.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.linkedin.com/jobs/view/4030963908/?eBP=CwEAAAGSRiAlnNccT2c14KIeiUtm-RaNdHLhuYx36SW8dLApHAc2Fwv46AAtOhxQDgMSxM0665BkEaYiaRoe7PvPPo2LKbErhgwsblbH78A9S7JrwMNIoLUx7ctdjhnhfbFIpv6kzqnKgHuFlLpNqL5j_f2gWd5tsuyddLj1_uATdcsE3AcB6G0k-Fp0ZuKQTMZSUnUJ8sS2JwiGEYkVYq0DSdv4NOeNn0S5wRwheRwcMdnFlMCzagsfV8Jg0ph5E4kD1c783ncF67m91iJUhzCneujDF-azXUmVb7Cbbpd8e5yMDNwWaTCkoU1zLBnFmiiXLzdgJyNs47HPZUgmnGydp9pU-CCeIOOOv9Y19mmSXaxOEh6VsrKAxrv2KOKuh0tjxs2-uVVB-slTLxDJlHn19RYvJt6wnfpwWZhscmGs_Mw94FRIj_E-XesTQmgbEIJv_HBVNgncF4-62k2aV7RpQHGjb_81wA&refId=vwSTfUVIpwofAdTjA650%2Bg%3D%3D&trackingId=HdHITNx6OWnhDY0QiTuLIw%3D%3D&trk=flagship3_search_srp_jobs\n",
      "Data: {'title': 'Director Search Engine Optimization', 'location': 'Wayne, PA (Hybrid)', 'description': \"About the job\\nSEO Director - Technical Focus\\n\\nWe're seeking an experienced SEO Director to lead our agency's search engine optimization efforts, with a particular emphasis on technical SEO. In this role, you'll drive organic growth for our clients through innovative strategies and cutting-edge technical optimizations.\\n\\nResponsibilities:\\n\\nTechnical SEO Leadership:\\n\\n- Spearhead technical SEO audits, identifying and prioritizing critical issues impacting site performance and search visibility\\n- Develop and implement advanced technical SEO strategies, including site architecture optimization, crawlability improvements, and indexation management\\n- Collaborate with development teams to review code and make cogent change requests that consider technical limitations\\n\\nStrategy and Execution:\\n\\n- Create comprehensive SEO roadmaps aligned with client KPIs and business objectives\\n- Oversee the execution of on-page and off-page SEO tactics, ensuring alignment with best practices and search engine guidelines\\n- Stay at the forefront of SEO trends, algorithm updates, and emerging technologies, incorporating new approaches into client strategies\\n- Develop and execute local SEO programs for both brick and mortar and service area type businesses\\n\\nTeam Management and Client Relations:\\n\\n- Lead and mentor a team of SEO specialists, fostering a culture of continuous learning and innovation\\n- Serve as the primary point of contact for high-priority clients, communicating complex SEO concepts in clear, actionable terms\\n- Collaborate with cross-functional teams to integrate SEO with broader digital marketing initiatives\\n - Help in the strategy development and planning for new business pitches as well as the delivery of the pitch\\n\\nRequirements:\\n\\n- 7+ years of SEO experience, with at least 2-3 years in a leadership role\\n- Deep expertise in technical SEO, including experience with JavaScript frameworks, e-commerce platforms, and various content management systems\\n- Strong analytical skills with proficiency in SEO tools like Google Search Console, Site Crawlers, BrightEdge, Conductor, Similarweb, Botify, etc.\\n- Proven track record of driving significant organic growth for clients through technical SEO optimizations\\n- Excellent project management abilities and experience leading cross-functional teams\\n- Strong communication skills, both written and verbal, with the ability to explain complex technical concepts to non-technical stakeholders\\n\\nPreferred Qualifications\\n\\n- Agency and in-house corporate experience preferred\\n- Advanced knowledge of HTML, CSS, and JavaScript\\n- Familiarity with log file analysis and large-scale data processing\\n- Experience with international SEO and hreflang implementation\\n- Understanding of machine learning (AI) and its applications in SEO\\n- Experience in planning and executing business pitches/proposals\\n\\nAt our agency, you'll have the opportunity to work with diverse clients, leverage cutting-edge SEO tools, and lead a team of talented professionals. If you're passionate about technical SEO and ready to drive organic growth at scale, we want to hear from you.\", 'applicants': '59 applicants', 'posted_time': '1 week ago'}\n"
     ]
    }
   ],
   "source": [
    "first_key = next(iter(loaded_job_dict))\n",
    "first_value = loaded_job_dict[first_key]\n",
    "\n",
    "print(f\"URL: {first_key}\")\n",
    "print(f\"Data: {first_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `JobLocationParser` Class\n",
    "\n",
    "Parses job location details and categorizes them into city, state, country, and place of work.\n",
    "\n",
    "---\n",
    "\n",
    "#### `__init__()` Method\n",
    "\n",
    "Initializes US state abbreviations, Canadian province abbreviations, and supported countries.\n",
    "\n",
    "---\n",
    "\n",
    "#### `extract_place_of_work(location)` Method\n",
    "\n",
    "Extracts and removes the work type (`Hybrid`, `On-site`, `Remote`) from the location string. Returns the work type and cleaned location.\n",
    "\n",
    "---\n",
    "\n",
    "#### `is_state_or_province(location_part)` Method\n",
    "\n",
    "Determines if a location part is a valid US state or Canadian province. Returns the state/province abbreviation and inferred country, or `None` if not found.\n",
    "\n",
    "---\n",
    "\n",
    "#### `categorize_location(location)` Method\n",
    "\n",
    "Splits the location into city, state, and country. Checks for a valid state/province and adds country information if applicable. Returns the categorized data.\n",
    "\n",
    "---\n",
    "\n",
    "#### `process_job_locations(job_dict)` Method\n",
    "\n",
    "Processes job location data in `job_dict`, categorizing each job's location into `city`, `state`, `country`, and `place_of_work`. Updates the job data with the new fields.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class JobLocationParser:\n",
    "    def __init__(self):\n",
    "        self.us_states = ['IA', 'KS', 'UT', 'VA', 'NC', 'NE', 'SD', 'AL', 'ID', 'FM', 'DE', 'AK', 'CT', 'PR', 'NM', 'MS', 'PW', 'CO', 'NJ', 'FL', 'MN', 'VI', 'NV', 'AZ', 'WI', 'ND', 'PA', 'OK', 'KY',\n",
    "                          'RI', 'NH', 'MO', 'ME', 'VT', 'GA', 'GU', 'AS', 'NY', 'CA', 'HI', 'IL', 'TN', 'MA', 'OH', 'MD', 'MI', 'WY', 'WA', 'OR', 'MH', 'SC', 'IN', 'LA', 'MP', 'DC', 'MT', 'AR', 'WV', 'TX']\n",
    "        self.can_province_abbrev = {\n",
    "            'Alberta': 'AB',\n",
    "            'British Columbia': 'BC',\n",
    "            'Manitoba': 'MB',\n",
    "            'New Brunswick': 'NB',\n",
    "            'Newfoundland and Labrador': 'NL',\n",
    "            'Northwest Territories': 'NT',\n",
    "            'Nova Scotia': 'NS',\n",
    "            'Nunavut': 'NU',\n",
    "            'Ontario': 'ON',\n",
    "            'Prince Edward Island': 'PE',\n",
    "            'Quebec': 'QC',\n",
    "            'Saskatchewan': 'SK',\n",
    "            'Yukon': 'YT',\n",
    "            'Labrador': 'NL',  # Labrador part of Newfoundland and Labrador\n",
    "            'Newfoundland': 'NL'  # Newfoundland part of Newfoundland and Labrador\n",
    "        }\n",
    "        self.countries = ['USA', 'Canada']\n",
    "\n",
    "    def extract_place_of_work(self, location):\n",
    "        \"\"\"Helper function to extract place of work (Hybrid/On-site/Remote) if present in the location string.\"\"\"\n",
    "        work_types = ['Hybrid', 'On-site', 'Remote']\n",
    "        for work_type in work_types:\n",
    "            if f\"({work_type})\" in location:\n",
    "                location = location.replace(f\"({work_type})\", \"\").strip()  # Remove place of work from location\n",
    "                return work_type, location\n",
    "        return \"NA\", location\n",
    "\n",
    "    def is_state_or_province(self, location_part):\n",
    "        \"\"\"Helper function to check if a given part of the location is a state or province.\"\"\"\n",
    "        if location_part in self.us_states:\n",
    "            return location_part, 'USA'\n",
    "        for province, abbrev in self.can_province_abbrev.items():\n",
    "            if location_part == province or location_part == abbrev:\n",
    "                return abbrev, 'Canada'\n",
    "        return None, None\n",
    "\n",
    "    def categorize_location(self, location):\n",
    "        # Step 1: Extract place of work (Hybrid/On-site/Remote) and clean location\n",
    "        place_of_work, location = self.extract_place_of_work(location)\n",
    "\n",
    "        # Step 2: Split by comma to extract city, state/region, and potentially country\n",
    "        location_map = location.split(\",\")\n",
    "        city, state, country = \"All\", \"All\", \"All\"  # Default values\n",
    "\n",
    "        if len(location_map) >= 2:  # Handle cases with city and state/province\n",
    "            city = location_map[0].strip()  # Assume city is the first part\n",
    "            state_info = location_map[1].split()  # Second part could be state/province\n",
    "\n",
    "            # Check if the second part is a valid state or province\n",
    "            potential_state = state_info[0].strip()\n",
    "            state_from_second_part, inferred_country = self.is_state_or_province(potential_state)\n",
    "\n",
    "            if state_from_second_part:\n",
    "                # Case: We found a valid state in the second part\n",
    "                state = state_from_second_part\n",
    "                country = inferred_country\n",
    "            else:\n",
    "                # Check if there is a third part for country information\n",
    "                if len(location_map) >= 3:\n",
    "                    potential_country = location_map[2].strip()\n",
    "                    if potential_country in self.countries:\n",
    "                        country = potential_country\n",
    "\n",
    "        elif len(location_map) == 1:  # Only one part present (maybe just state or province)\n",
    "            potential_state = location_map[0].strip()\n",
    "            state_from_first_part, inferred_country = self.is_state_or_province(potential_state)\n",
    "\n",
    "            if state_from_first_part:\n",
    "                # Case: Single part is a valid state or province, no city\n",
    "                state = state_from_first_part\n",
    "                country = inferred_country\n",
    "            else:\n",
    "                # Case: No valid state or province\n",
    "                city = location_map[0].strip()  # Keep it as city\n",
    "                state = \"All\"\n",
    "\n",
    "        return {\n",
    "            \"city\": city,\n",
    "            \"state\": state,\n",
    "            \"country\": country,\n",
    "            \"place_of_work\": place_of_work\n",
    "        }\n",
    "\n",
    "    def process_job_locations(self, job_dict):\n",
    "        for url, job_data in job_dict.items():\n",
    "            # Get the location from the job data\n",
    "            location = job_data['location']\n",
    "            \n",
    "            # Categorize the location into city, state, country, and place_of_work\n",
    "            categorized_location = self.categorize_location(location)\n",
    "            \n",
    "            # Add new fields to the job data\n",
    "            job_data['city'] = categorized_location['city']\n",
    "            job_data['state'] = categorized_location['state']\n",
    "            job_data['country'] = categorized_location['country']\n",
    "            job_data['place_of_work'] = categorized_location['place_of_work']\n",
    "\n",
    "        return job_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initializing the class and processeing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jlp = JobLocationParser()\n",
    "loaded_job_dict_loc = jlp.process_job_locations(loaded_job_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.linkedin.com/jobs/view/4030963908/?eBP=CwEAAAGSRiAlnNccT2c14KIeiUtm-RaNdHLhuYx36SW8dLApHAc2Fwv46AAtOhxQDgMSxM0665BkEaYiaRoe7PvPPo2LKbErhgwsblbH78A9S7JrwMNIoLUx7ctdjhnhfbFIpv6kzqnKgHuFlLpNqL5j_f2gWd5tsuyddLj1_uATdcsE3AcB6G0k-Fp0ZuKQTMZSUnUJ8sS2JwiGEYkVYq0DSdv4NOeNn0S5wRwheRwcMdnFlMCzagsfV8Jg0ph5E4kD1c783ncF67m91iJUhzCneujDF-azXUmVb7Cbbpd8e5yMDNwWaTCkoU1zLBnFmiiXLzdgJyNs47HPZUgmnGydp9pU-CCeIOOOv9Y19mmSXaxOEh6VsrKAxrv2KOKuh0tjxs2-uVVB-slTLxDJlHn19RYvJt6wnfpwWZhscmGs_Mw94FRIj_E-XesTQmgbEIJv_HBVNgncF4-62k2aV7RpQHGjb_81wA&refId=vwSTfUVIpwofAdTjA650%2Bg%3D%3D&trackingId=HdHITNx6OWnhDY0QiTuLIw%3D%3D&trk=flagship3_search_srp_jobs\n",
      "Data: {'title': 'Director Search Engine Optimization', 'location': 'Wayne, PA (Hybrid)', 'description': \"About the job\\nSEO Director - Technical Focus\\n\\nWe're seeking an experienced SEO Director to lead our agency's search engine optimization efforts, with a particular emphasis on technical SEO. In this role, you'll drive organic growth for our clients through innovative strategies and cutting-edge technical optimizations.\\n\\nResponsibilities:\\n\\nTechnical SEO Leadership:\\n\\n- Spearhead technical SEO audits, identifying and prioritizing critical issues impacting site performance and search visibility\\n- Develop and implement advanced technical SEO strategies, including site architecture optimization, crawlability improvements, and indexation management\\n- Collaborate with development teams to review code and make cogent change requests that consider technical limitations\\n\\nStrategy and Execution:\\n\\n- Create comprehensive SEO roadmaps aligned with client KPIs and business objectives\\n- Oversee the execution of on-page and off-page SEO tactics, ensuring alignment with best practices and search engine guidelines\\n- Stay at the forefront of SEO trends, algorithm updates, and emerging technologies, incorporating new approaches into client strategies\\n- Develop and execute local SEO programs for both brick and mortar and service area type businesses\\n\\nTeam Management and Client Relations:\\n\\n- Lead and mentor a team of SEO specialists, fostering a culture of continuous learning and innovation\\n- Serve as the primary point of contact for high-priority clients, communicating complex SEO concepts in clear, actionable terms\\n- Collaborate with cross-functional teams to integrate SEO with broader digital marketing initiatives\\n - Help in the strategy development and planning for new business pitches as well as the delivery of the pitch\\n\\nRequirements:\\n\\n- 7+ years of SEO experience, with at least 2-3 years in a leadership role\\n- Deep expertise in technical SEO, including experience with JavaScript frameworks, e-commerce platforms, and various content management systems\\n- Strong analytical skills with proficiency in SEO tools like Google Search Console, Site Crawlers, BrightEdge, Conductor, Similarweb, Botify, etc.\\n- Proven track record of driving significant organic growth for clients through technical SEO optimizations\\n- Excellent project management abilities and experience leading cross-functional teams\\n- Strong communication skills, both written and verbal, with the ability to explain complex technical concepts to non-technical stakeholders\\n\\nPreferred Qualifications\\n\\n- Agency and in-house corporate experience preferred\\n- Advanced knowledge of HTML, CSS, and JavaScript\\n- Familiarity with log file analysis and large-scale data processing\\n- Experience with international SEO and hreflang implementation\\n- Understanding of machine learning (AI) and its applications in SEO\\n- Experience in planning and executing business pitches/proposals\\n\\nAt our agency, you'll have the opportunity to work with diverse clients, leverage cutting-edge SEO tools, and lead a team of talented professionals. If you're passionate about technical SEO and ready to drive organic growth at scale, we want to hear from you.\", 'applicants': '59 applicants', 'posted_time': '1 week ago', 'city': 'Wayne', 'state': 'PA', 'country': 'USA', 'place_of_work': 'Hybrid'}\n"
     ]
    }
   ],
   "source": [
    "first_key = next(iter(loaded_job_dict_loc))\n",
    "first_value = loaded_job_dict_loc[first_key]\n",
    "\n",
    "print(f\"URL: {first_key}\")\n",
    "print(f\"Data: {first_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Saving the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to job_dict_full_usa_loc.p\n"
     ]
    }
   ],
   "source": [
    "save(\"job_dict_full_usa_loc\", loaded_job_dict_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded from job_dict_full_usa_loc.p\n"
     ]
    }
   ],
   "source": [
    "job_dict_full_usa_loc = load(\"job_dict_full_usa_loc.p\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert job dictionary to DataFrame, clean data by droping extra columns, and export to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "df = pd.DataFrame.from_dict(job_dict_full_usa_loc, orient='index')\n",
    "\n",
    "# Drop the unwanted columns (if applicable)\n",
    "df = df.drop(columns=['posted_time', 'applicants'], errors='ignore')\n",
    "\n",
    "# Reset the index so that URLs become a regular column\n",
    "df = df.reset_index()\n",
    "\n",
    "# Rename the 'index' column to 'url'\n",
    "df = df.rename(columns={'index': 'url'})\n",
    "\n",
    "# Write the DataFrame to a CSV file without the index\n",
    "df.to_csv('linkedin_jobs_filtered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
