{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Methodology for Cleaning the Job Description\n",
    "\n",
    "1. **Remove HTML Tags (if present)**:\n",
    "   - Job descriptions scraped from LinkedIn may contain HTML tags. We use `BeautifulSoup` to remove these tags while preserving the text content for cleaner analysis.\n",
    "\n",
    "2. **Remove Unnecessary Line Breaks and Whitespace**:\n",
    "   - Multiple line breaks or extra spaces can clutter the description. We use regular expressions to replace them with single spaces for a cleaner and more readable description.\n",
    "\n",
    "3. **Lowercase Transformation**:\n",
    "   - Converting all text to lowercase ensures uniformity, especially important when matching skills, keywords, or performing text analysis.\n",
    "\n",
    "4. **Remove Special Characters and Punctuation**:\n",
    "   - We remove unnecessary special characters (e.g., #, $, @) while retaining meaningful punctuation like colons and commas to maintain sentence structure without adding noise.\n",
    "\n",
    "5. **Remove Stopwords**:\n",
    "   - Stopwords like \"the,\" \"and,\" or \"in\" do not provide significant meaning, so we remove them to focus on the key information in the text.\n",
    "\n",
    "6. **Lemmatization**:\n",
    "   - We apply lemmatization to reduce words to their root form (e.g., \"running\" to \"run\") for better consistency when analyzing or matching words in the description.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `clean_description(description)` Function\n",
    "\n",
    "This function performs text preprocessing on job descriptions to clean and standardize the content. The steps in the cleaning process are outlined below:\n",
    "\n",
    "1. **HTML Tag Removal**:\n",
    "   - Uses `BeautifulSoup` to remove any HTML tags present in the description, leaving only the text.\n",
    "\n",
    "2. **Whitespace Cleanup**:\n",
    "   - Removes unnecessary line breaks, multiple spaces, and trims any leading or trailing whitespace using regular expressions.\n",
    "\n",
    "3. **Lowercase Transformation**:\n",
    "   - Converts all text to lowercase to ensure consistency in further text processing.\n",
    "\n",
    "4. **Special Character Removal**:\n",
    "   - Removes special characters and punctuation, but retains essential punctuation like colons, commas, and periods to preserve the structure of the text.\n",
    "\n",
    "5. **Stopword Removal**:\n",
    "   - Filters out common stopwords (like \"the\", \"is\", \"and\") using the NLTK stopwords list, reducing noise in the description.\n",
    "\n",
    "6. **Lemmatization**:\n",
    "   - Applies lemmatization using `WordNetLemmatizer` to reduce words to their base form, ensuring that different forms of a word (e.g., \"running\", \"ran\") are treated as the same word.\n",
    "\n",
    "This process cleans, simplifies, and standardizes the job descriptions, making them more suitable for text analysis or machine learning tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_description(description):\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # 1. Remove HTML Tags\n",
    "    soup = BeautifulSoup(description, \"html.parser\")\n",
    "    cleaned_description = soup.get_text()\n",
    "\n",
    "    # 2. Remove Unnecessary Line Breaks and Whitespace\n",
    "    cleaned_description = re.sub(r'\\s+', ' ', cleaned_description).strip()\n",
    "\n",
    "    # 3. Lowercase Transformation\n",
    "    cleaned_description = cleaned_description.lower()\n",
    "\n",
    "\n",
    "    # 4. Remove Special Characters and Punctuation (retain colons, commas, and periods)\n",
    "    cleaned_description = re.sub(r'[^\\w\\s.,:]', '', cleaned_description)\n",
    "\n",
    "    # 5. Remove Stopwords\n",
    "    cleaned_description = ' '.join([word for word in cleaned_description.split() if word not in stop_words])\n",
    "\n",
    "    # 6. Lemmatization\n",
    "    cleaned_description = ' '.join([lemmatizer.lemmatize(word) for word in cleaned_description.split()])\n",
    "\n",
    "    return cleaned_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(r\"linkedin_jobs_filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>place_of_work</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4030963908/...</td>\n",
       "      <td>Director Search Engine Optimization</td>\n",
       "      <td>Wayne, PA (Hybrid)</td>\n",
       "      <td>About the job\\nSEO Director - Technical Focus\\...</td>\n",
       "      <td>Wayne</td>\n",
       "      <td>PA</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4034610554/...</td>\n",
       "      <td>SAP Hana Project Manager</td>\n",
       "      <td>Naperville, IL (On-site)</td>\n",
       "      <td>About the job\\nThe Business Systems Project Ma...</td>\n",
       "      <td>Naperville</td>\n",
       "      <td>IL</td>\n",
       "      <td>On-site</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4030614251/...</td>\n",
       "      <td>Tech-Savvy Financial Planner</td>\n",
       "      <td>Las Vegas, NV (Hybrid)</td>\n",
       "      <td>About the job\\nJob Title: Tech-Savvy Financial...</td>\n",
       "      <td>Las Vegas</td>\n",
       "      <td>NV</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4026434663/...</td>\n",
       "      <td>Class C Licensed Groundwater Plant Operator</td>\n",
       "      <td>Houston, TX (On-site)</td>\n",
       "      <td>About the job\\nWe are seeking an experienced C...</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>On-site</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.linkedin.com/jobs/view/4022898839/...</td>\n",
       "      <td>ILI Specialist</td>\n",
       "      <td>Houston, TX (Hybrid)</td>\n",
       "      <td>About the job\\nCompany Description\\nD2 Integri...</td>\n",
       "      <td>Houston</td>\n",
       "      <td>TX</td>\n",
       "      <td>Hybrid</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.linkedin.com/jobs/view/4030963908/...   \n",
       "1  https://www.linkedin.com/jobs/view/4034610554/...   \n",
       "2  https://www.linkedin.com/jobs/view/4030614251/...   \n",
       "3  https://www.linkedin.com/jobs/view/4026434663/...   \n",
       "4  https://www.linkedin.com/jobs/view/4022898839/...   \n",
       "\n",
       "                                         title                  location  \\\n",
       "0          Director Search Engine Optimization        Wayne, PA (Hybrid)   \n",
       "1                     SAP Hana Project Manager  Naperville, IL (On-site)   \n",
       "2                 Tech-Savvy Financial Planner    Las Vegas, NV (Hybrid)   \n",
       "3  Class C Licensed Groundwater Plant Operator     Houston, TX (On-site)   \n",
       "4                               ILI Specialist      Houston, TX (Hybrid)   \n",
       "\n",
       "                                         description        city state  \\\n",
       "0  About the job\\nSEO Director - Technical Focus\\...       Wayne    PA   \n",
       "1  About the job\\nThe Business Systems Project Ma...  Naperville    IL   \n",
       "2  About the job\\nJob Title: Tech-Savvy Financial...   Las Vegas    NV   \n",
       "3  About the job\\nWe are seeking an experienced C...     Houston    TX   \n",
       "4  About the job\\nCompany Description\\nD2 Integri...     Houston    TX   \n",
       "\n",
       "  place_of_work country  \n",
       "0        Hybrid     USA  \n",
       "1       On-site     USA  \n",
       "2        Hybrid     USA  \n",
       "3       On-site     USA  \n",
       "4        Hybrid     USA  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   url            1000 non-null   object\n",
      " 1   title          1000 non-null   object\n",
      " 2   location       1000 non-null   object\n",
      " 3   description    1000 non-null   object\n",
      " 4   city           1000 non-null   object\n",
      " 5   state          1000 non-null   object\n",
      " 6   place_of_work  946 non-null    object\n",
      " 7   country        1000 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 62.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    About the job\\nSEO Director - Technical Focus\\...\n",
       "1    About the job\\nThe Business Systems Project Ma...\n",
       "2    About the job\\nJob Title: Tech-Savvy Financial...\n",
       "3    About the job\\nWe are seeking an experienced C...\n",
       "4    About the job\\nCompany Description\\nD2 Integri...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['description'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of Sentence Splitting\n",
    "\n",
    "This function splits a job description into individual sentences, preparing the text for further analysis. The goal is to manually tag each sentence as either \"Qualified\" or \"Description\" based on its relevance. This tagging process will help build a labeled dataset that can be used to train machine learning models for automated classification of job description sentences.\n",
    "\n",
    "---\n",
    "\n",
    "### `split_into_sentences(text)` Function\n",
    "\n",
    "1. **Load spaCy's English Model**:\n",
    "   - We use spaCy's `en_core_web_sm` model to handle sentence tokenization. This model is pre-trained to understand English syntax and structure.\n",
    "\n",
    "2. **Split Text by New Lines**:\n",
    "   - The text is first split by new line characters (`\\n`) to break down paragraphs or sections.\n",
    "\n",
    "3. **Sentence Segmentation**:\n",
    "   - Each paragraph is processed using spaCy's sentence tokenizer. This extracts individual sentences from the text, allowing for precise sentence splitting based on language rules.\n",
    "\n",
    "4. **Remove Leading Hyphens**:\n",
    "   - Some sentences may start with hyphens (e.g., bullet points). We strip leading hyphens to clean up the sentences for easier tagging and processing.\n",
    "\n",
    "5. **Return Cleaned Sentences**:\n",
    "   - The function returns a list of cleaned, split sentences, ready for manual tagging or further processing.\n",
    "\n",
    "This approach ensures that the job description is split into clear, usable sentences, facilitating the next step of manual tagging for model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split text into sentences, handle new lines, and remove leading hyphens\n",
    "def split_into_sentences(text):\n",
    "    # Split the text by new lines first\n",
    "    paragraphs = text.split('\\n')\n",
    "    sentences = []\n",
    "    \n",
    "    for paragraph in paragraphs:\n",
    "        # Process each paragraph with spaCy\n",
    "        doc = nlp(paragraph)\n",
    "        # Extract sentences and add to the list, removing leading hyphens\n",
    "        for sent in doc.sents:\n",
    "            cleaned_sentence = sent.text.strip()\n",
    "            if cleaned_sentence.startswith('-'):\n",
    "                cleaned_sentence = cleaned_sentence[1:].strip()  # Remove leading hyphen\n",
    "            sentences.append(cleaned_sentence)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply to dataset\n",
    "data['sentences'] = data['description'].apply(split_into_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to hold the exploded sentences\n",
    "sentences_df = pd.DataFrame(data['sentences'].explode()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About the job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEO Director - Technical Focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We're seeking an experienced SEO Director to l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this role, you'll drive organic growth for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Responsibilities:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>Program Management:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>Proven experience in managing multiple Data an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40004</th>\n",
       "      <td>Agile Methodology: Strong experience with Agil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40005</th>\n",
       "      <td>Industry Experience: Experience in the life sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40006</th>\n",
       "      <td>Presentation skills : Presen the program accom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40007 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences\n",
       "0                                          About the job\n",
       "1                         SEO Director - Technical Focus\n",
       "2      We're seeking an experienced SEO Director to l...\n",
       "3      In this role, you'll drive organic growth for ...\n",
       "4                                      Responsibilities:\n",
       "...                                                  ...\n",
       "40002                                Program Management:\n",
       "40003  Proven experience in managing multiple Data an...\n",
       "40004  Agile Methodology: Strong experience with Agil...\n",
       "40005  Industry Experience: Experience in the life sc...\n",
       "40006  Presentation skills : Presen the program accom...\n",
       "\n",
       "[40007 rows x 1 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df['cleaned_sentence'] = sentences_df['sentences'].apply(clean_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cleaning the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>cleaned_sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>About the job</td>\n",
       "      <td>job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEO Director - Technical Focus</td>\n",
       "      <td>seo director technical focus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We're seeking an experienced SEO Director to l...</td>\n",
       "      <td>seeking experienced seo director lead agency s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In this role, you'll drive organic growth for ...</td>\n",
       "      <td>role, youll drive organic growth client innova...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Responsibilities:</td>\n",
       "      <td>responsibilities:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40002</th>\n",
       "      <td>Program Management:</td>\n",
       "      <td>program management:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40003</th>\n",
       "      <td>Proven experience in managing multiple Data an...</td>\n",
       "      <td>proven experience managing multiple data bi pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40004</th>\n",
       "      <td>Agile Methodology: Strong experience with Agil...</td>\n",
       "      <td>agile methodology: strong experience agile met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40005</th>\n",
       "      <td>Industry Experience: Experience in the life sc...</td>\n",
       "      <td>industry experience: experience life science p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40006</th>\n",
       "      <td>Presentation skills : Presen the program accom...</td>\n",
       "      <td>presentation skill : presen program accomplish...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40007 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               sentences  \\\n",
       "0                                          About the job   \n",
       "1                         SEO Director - Technical Focus   \n",
       "2      We're seeking an experienced SEO Director to l...   \n",
       "3      In this role, you'll drive organic growth for ...   \n",
       "4                                      Responsibilities:   \n",
       "...                                                  ...   \n",
       "40002                                Program Management:   \n",
       "40003  Proven experience in managing multiple Data an...   \n",
       "40004  Agile Methodology: Strong experience with Agil...   \n",
       "40005  Industry Experience: Experience in the life sc...   \n",
       "40006  Presentation skills : Presen the program accom...   \n",
       "\n",
       "                                        cleaned_sentence  \n",
       "0                                                    job  \n",
       "1                           seo director technical focus  \n",
       "2      seeking experienced seo director lead agency s...  \n",
       "3      role, youll drive organic growth client innova...  \n",
       "4                                      responsibilities:  \n",
       "...                                                  ...  \n",
       "40002                                program management:  \n",
       "40003  proven experience managing multiple data bi pr...  \n",
       "40004  agile methodology: strong experience agile met...  \n",
       "40005  industry experience: experience life science p...  \n",
       "40006  presentation skill : presen program accomplish...  \n",
       "\n",
       "[40007 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_df.to_csv('processed_data.csv', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
